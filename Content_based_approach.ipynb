{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647eb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import chain\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.family'] = 'sans-serif' \n",
    "plt.rcParams['font.serif'] = 'Ubuntu' \n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono' \n",
    "plt.rcParams['font.size'] = 14 \n",
    "plt.rcParams['axes.labelsize'] = 12 \n",
    "plt.rcParams['axes.labelweight'] = 'bold' \n",
    "plt.rcParams['axes.titlesize'] = 12 \n",
    "plt.rcParams['xtick.labelsize'] = 12 \n",
    "plt.rcParams['ytick.labelsize'] = 12 \n",
    "plt.rcParams['legend.fontsize'] = 12 \n",
    "plt.rcParams['figure.titlesize'] = 12 \n",
    "plt.rcParams['image.cmap'] = 'jet' \n",
    "plt.rcParams['image.interpolation'] = 'none' \n",
    "plt.rcParams['figure.figsize'] = (12, 10) \n",
    "plt.rcParams['axes.grid']=True\n",
    "plt.rcParams['lines.linewidth'] = 2 \n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "colors = ['xkcd:pale orange', 'xkcd:sea blue', 'xkcd:pale red', 'xkcd:sage green', 'xkcd:terra cotta', 'xkcd:dull purple', 'xkcd:teal', 'xkcd: goldenrod', 'xkcd:cadet blue',\n",
    "'xkcd:scarlet']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4b850",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80a9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('5p_books.pickle')\n",
    "data = data.sample(frac = 0.25, random_state=57, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa26acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.loc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37e0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text:str, nlp, lemmatize = False):\n",
    "    \"\"\"\n",
    "    Use spacy lemmatizer to tokenize or lemmatize text. Remove stopwords, punctuation\n",
    "    Input: text (string)\n",
    "    Output: list of tokens \"\"\"\n",
    "    if lemmatize:\n",
    "        return ' '.join([token.lemma_ for token in nlp(text.strip(), disable=[\"parser\", \"ner\"]) if not token.is_stop and not token.is_punct ])\n",
    "    else:\n",
    "        \n",
    "        text = ' '.join([token.text for token in nlp(text.strip()) \n",
    "                     if not token.like_email and not token.like_url and not token.is_space ])\n",
    "\n",
    "        return text\n",
    "\n",
    "def genre_extractor(d):\n",
    "    \"\"\"Extract keys from dict into a flatten list\"\"\"\n",
    "    keys = [key.split(',') for key in d.keys()]\n",
    "    keys = list(chain(*keys))\n",
    "    keys = [key.strip() for key in keys]\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def unpack_list(l):\n",
    "    \"\"\"Unpack elements of a list and join them into a string\"\"\"\n",
    "    return ', '.join([item for item in l])\n",
    "\n",
    "# print(genre_extractor(df.genres.iloc[0]))\n",
    "# print(unpack_list(df.series.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2461ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty rows\n",
    "data = data.dropna(how = 'all')\n",
    "#Get list of genres\n",
    "data['genres_key'] = data['genres'].apply(genre_extractor)\n",
    "#Lemmatize, remove stopwords, punctuation\n",
    "data['Clean_description'] = data.description#.apply(text_process, nlp = nlp, lemmatize = False)\n",
    "# unpacking lists\n",
    "data['genres_key'] = data.genres_key.apply(unpack_list)\n",
    "data['series'] = data.series.apply(unpack_list)\n",
    "data['similar_books'] = data.similar_books.apply(unpack_list)\n",
    "data['authors']= data.authors.apply(unpack_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5d097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the sentence transformer model\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df5d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "columns =['Clean_description', 'authors','title_without_series', 'publisher','series', 'genres_key', 'is_ebook', 'similar_books', 'format', 'num_pages', 'publication_year']\n",
    "data_ = data[['Clean_description', 'authors','title_without_series', 'publisher','series', 'genres_key', 'is_ebook', 'similar_books', 'format', 'num_pages', 'publication_year']]\n",
    "for col in columns :\n",
    "    print(type(data[col].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "208df8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(columns)\n",
    "d = data.shape[0]\n",
    "sims = np.zeros([n, d, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e56e3d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean_description\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975f306ecc8c4ff7a6ea1d61d52117e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdaaa4f39e1443980e7548913c648b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_without_series\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d2e0196494ebcb1610769570f1a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552300068416423a88648e661afcfe95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee6e0725f5143649123ffa962fd9b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres_key\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f72d6bdcfc48f1ab26d4399f5e7b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ebook\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b452ef65e371435e9498b70d33e0a951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar_books\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f3348ca2cc499ba3601131512fd32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b894d596734062992878132e00985c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8603afb07969422a884e613094334e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publication_year\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86586c5121ea401499bb6d6eca8171e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "for col in  columns:\n",
    "      \n",
    "    \n",
    "    print(col)\n",
    "#     if X is not str:\n",
    "#         print('not str')\n",
    "#         X = data[col].apply(lambda x : x[0] if len(X)>0 else '')\n",
    "#         # for word in X : \n",
    "#         #     X2 = X2 + word[0]  \n",
    "    #Convert description column in data_ DataFrame to numpy array\n",
    "    X = np.array(data[col])\n",
    "    # Convert the data to string type\n",
    "    X = X.astype(str)\n",
    "    # Get the embeddings for the text data\n",
    "    text_data = X\n",
    "    embeddings = model.encode(text_data, show_progress_bar=True)\n",
    "#     if count == 1 :\n",
    "#         X_st = embeddings\n",
    "#     else:\n",
    "#         X_st = np.column_stack((X_st, embeddings))\n",
    "    sims[count, :, :] = cosine_similarity(embeddings)\n",
    "    count += 1  \n",
    "#     print(X_st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7524f66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9\n"
     ]
    }
   ],
   "source": [
    "coefficients = {\n",
    "    'Clean_description':5,\n",
    "    'authors':1,\n",
    "    'title_without_series':1,\n",
    "    'publisher':1,\n",
    "    'series':1,\n",
    "    'genres_key':0,\n",
    "    'is_ebook':0.5,\n",
    "    'similar_books':0.1,\n",
    "    'format':0.3,\n",
    "    'num_pages':1,\n",
    "    'publication_year':1,\n",
    "}\n",
    "normalization = 0\n",
    "for k, v in coefficients.items():\n",
    "    normalization += v\n",
    "print(normalization)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ce97b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_total = np.zeros([d,d])\n",
    "for i , col in zip(range(n), columns):\n",
    "    sims_total += sims[i, : , :]*coefficients[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bc0911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999998, 0.49303222, 0.64209377, ..., 0.57587751, 0.53909279,\n",
       "        0.57535585],\n",
       "       [0.49303222, 0.99999986, 0.5470101 , ..., 0.46407578, 0.41969817,\n",
       "        0.52544527],\n",
       "       [0.64209377, 0.5470101 , 0.99999983, ..., 0.63169989, 0.5779965 ,\n",
       "        0.61852838],\n",
       "       ...,\n",
       "       [0.57587751, 0.46407578, 0.63169989, ..., 0.99999999, 0.57883696,\n",
       "        0.67467715],\n",
       "       [0.53909279, 0.41969817, 0.5779965 , ..., 0.57883696, 1.00000011,\n",
       "        0.58645966],\n",
       "       [0.57535585, 0.52544527, 0.61852838, ..., 0.67467715, 0.58645966,\n",
       "        0.99999993]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_total/normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d0784e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.000000\n",
       "1       0.453980\n",
       "2       0.712427\n",
       "3      -0.008874\n",
       "4       0.626640\n",
       "          ...   \n",
       "996     0.683792\n",
       "997     0.630460\n",
       "998     0.691473\n",
       "999     0.585552\n",
       "1000    0.655160\n",
       "Name: 0, Length: 1001, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35100231",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_data = pd.DataFrame(sims_total/normalization)\n",
    "def give_recommendations(index, features=[]):\n",
    "    # Get the 5 most similar book indexes to the input index\n",
    "    index_recomm = cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:6]\n",
    "    # Get the titles of the 5 most similar books\n",
    "    books_recomm = data['title_without_series'].loc[index_recomm].values\n",
    "    # Store the titles and indexes of the recommended books in a dictionary\n",
    "    result = {'Books': books_recomm, 'Index': index_recomm}\n",
    "\n",
    "    # If 'recommendation' is in the list of features, print the read book and the recommended books\n",
    "    if 'recommendation' in features:\n",
    "        print('The read book is this one: %s \\n' % (data['title_without_series'].loc[index]))\n",
    "        for i, book in enumerate(books_recomm):\n",
    "            print(f'The number {i + 1} recommended book is this one: {book} \\n')\n",
    "\n",
    "    # Loop over the features list and print the value of each feature for the read book and the recommended books\n",
    "    if 'Clean_description' in features:\n",
    "        print('The plot of the read book is this one:\\n %s \\n' % (data['Clean_description'].loc[index]))\n",
    "        for i in range(len(books_recomm)):\n",
    "            plot_q = data['Clean_description'].loc[index_recomm[i]]\n",
    "            print(f'The plot of the number {i + 1} recommended book is this one:\\n {plot_q} \\n')\n",
    "\n",
    "    # Loop over the features list and print the value of each feature for the read book and the recommended books\n",
    "    for feature in ['authors', 'publisher', 'series', 'is_ebook', 'similar_books', 'genres_key', 'format', 'num_pages', 'publication_year']:\n",
    "        if feature in features:\n",
    "            print(f'The {feature} of the read book is this one:\\n {data[feature].loc[index]} \\n')\n",
    "            for i in range(len(books_recomm)):\n",
    "                print(f'The {feature} of the number {i + 1} recommended book is this one:\\n {data[feature].loc[index_recomm[i]]} \\n')\n",
    "                \n",
    "    # Return the result dictionary\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84e947d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomm_list = []\n",
    "# Loop through all items in X \n",
    "for i in range(data.shape[0]):\n",
    "  # Get the recommendations for each item by calling give_recommendations() function\n",
    "  recomm_i = give_recommendations(i)\n",
    "  # Store the recommended books for each item in the list \"recomm_list\"\n",
    "  recomm_list.append(recomm_i['Books'])\n",
    "recomm_data = pd.DataFrame(recomm_list,columns=['First Recommendation','Second Recommendation','Third Recommendation','Fourth Recommendation','Fifth Recommendation'])\n",
    "# Create a dataframe \"recomm_data\" from \"recomm_list\" with columns for each recommended book and \"Read Book\"\n",
    "recomm_data['Read Book'] = data['title_without_series']\n",
    "# Reorder the columns to show \"Read Book\" first, followed by the 5 recommended books.\n",
    "recomm_data = recomm_data[['Read Book','First Recommendation','Second Recommendation','Third Recommendation','Fourth Recommendation','Fifth Recommendation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f413b0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Read Book</th>\n",
       "      <th>First Recommendation</th>\n",
       "      <th>Second Recommendation</th>\n",
       "      <th>Third Recommendation</th>\n",
       "      <th>Fourth Recommendation</th>\n",
       "      <th>Fifth Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>The Gomorrah Principle</td>\n",
       "      <td>Sleeper Cell</td>\n",
       "      <td>Spinner of Yarns</td>\n",
       "      <td>Journal of a Cavalry Bugler</td>\n",
       "      <td>Steel Hearts</td>\n",
       "      <td>This Is Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>The Alleyman (No Man's World, #3)</td>\n",
       "      <td>Out of Nowhere</td>\n",
       "      <td>Wrath of the Lemming Men (Chronicles of Isamba...</td>\n",
       "      <td>Shockwave (Urban Outlaws, #5)</td>\n",
       "      <td>Pubs, Pulpits &amp; Prairie Fires</td>\n",
       "      <td>Clawed!: A Choose Your Own Ending Horror Adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>A Corkscrew is Most Useful: The Travellers of ...</td>\n",
       "      <td>Contemporary Marketing 2011</td>\n",
       "      <td>How to Succeed in the Game of Life: 34 Intervi...</td>\n",
       "      <td>Pubs, Pulpits &amp; Prairie Fires</td>\n",
       "      <td>Alone Beneath the Heaven: A gripping saga of e...</td>\n",
       "      <td>Lee de Forest: King of Radio, Television, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>The Snow Queen (Tales of the Five Hundred King...</td>\n",
       "      <td>The Secret Life of Ancient Bristlecone Pines</td>\n",
       "      <td>Enchantress, Sorceress, Madwoman: The True Sto...</td>\n",
       "      <td>THE PROMISE - THE ISLAND OF COMMITMENT (HUGO T...</td>\n",
       "      <td>Lady Bird: A Biography of Mrs. Johnson</td>\n",
       "      <td>Christmas Stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Foretold (Daughters Of Saraqael, #3)</td>\n",
       "      <td>Getting It Right This Time</td>\n",
       "      <td>Froi of the Exiles (Lumatere Chronicles, #2)</td>\n",
       "      <td>Spring Comes to Sanctuary (Welcome to Sanctuar...</td>\n",
       "      <td>Merle und die Fließende Königin (Merle-Trilogi...</td>\n",
       "      <td>Motherlines (Holdfast Chronicles, #2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Read Book  \\\n",
       "210                             The Gomorrah Principle   \n",
       "523                  The Alleyman (No Man's World, #3)   \n",
       "518  A Corkscrew is Most Useful: The Travellers of ...   \n",
       "470  The Snow Queen (Tales of the Five Hundred King...   \n",
       "660               Foretold (Daughters Of Saraqael, #3)   \n",
       "\n",
       "                             First Recommendation  \\\n",
       "210                                  Sleeper Cell   \n",
       "523                                Out of Nowhere   \n",
       "518                   Contemporary Marketing 2011   \n",
       "470  The Secret Life of Ancient Bristlecone Pines   \n",
       "660                    Getting It Right This Time   \n",
       "\n",
       "                                 Second Recommendation  \\\n",
       "210                                   Spinner of Yarns   \n",
       "523  Wrath of the Lemming Men (Chronicles of Isamba...   \n",
       "518  How to Succeed in the Game of Life: 34 Intervi...   \n",
       "470  Enchantress, Sorceress, Madwoman: The True Sto...   \n",
       "660       Froi of the Exiles (Lumatere Chronicles, #2)   \n",
       "\n",
       "                                  Third Recommendation  \\\n",
       "210                        Journal of a Cavalry Bugler   \n",
       "523                      Shockwave (Urban Outlaws, #5)   \n",
       "518                      Pubs, Pulpits & Prairie Fires   \n",
       "470  THE PROMISE - THE ISLAND OF COMMITMENT (HUGO T...   \n",
       "660  Spring Comes to Sanctuary (Welcome to Sanctuar...   \n",
       "\n",
       "                                 Fourth Recommendation  \\\n",
       "210                                       Steel Hearts   \n",
       "523                      Pubs, Pulpits & Prairie Fires   \n",
       "518  Alone Beneath the Heaven: A gripping saga of e...   \n",
       "470             Lady Bird: A Biography of Mrs. Johnson   \n",
       "660  Merle und die Fließende Königin (Merle-Trilogi...   \n",
       "\n",
       "                                  Fifth Recommendation  \n",
       "210                                       This Is Life  \n",
       "523  Clawed!: A Choose Your Own Ending Horror Adven...  \n",
       "518  Lee de Forest: King of Radio, Television, and ...  \n",
       "470                                 Christmas Stranger  \n",
       "660              Motherlines (Holdfast Chronicles, #2)  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the data and return the first 5 rows as a sample\n",
    "recomm_data.sample(frac=1).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
